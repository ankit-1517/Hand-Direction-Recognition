{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from time import time\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import cv2 as cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_value= 0\n",
    "\n",
    "import os\n",
    "os.environ['PYTHONHASHSEED']=str(seed_value)\n",
    "\n",
    "import random\n",
    "random.seed(seed_value)\n",
    "\n",
    "import numpy as np\n",
    "np.random.seed(seed_value)\n",
    "\n",
    "import tensorflow as tf\n",
    "tf.set_random_seed(seed_value)\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Input, Flatten, Dense, Dropout, Convolution2D, Conv2D, MaxPooling2D, Lambda, GlobalMaxPooling2D, GlobalAveragePooling2D, BatchNormalization, Activation, AveragePooling2D, Concatenate\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from keras.utils import np_utils\n",
    "from keras import backend as K\n",
    "session_conf = tf.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n",
    "sess = tf.Session(graph=tf.get_default_graph(), config=session_conf)\n",
    "K.set_session(sess)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getOneHot(a):\n",
    "    b = np.zeros((a.size, a.max()+1))\n",
    "    b[np.arange(a.size),a] = 1\n",
    "    return b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getData(path, folders):\n",
    "    path+='/'\n",
    "    labelNames = folders\n",
    "    labels = []\n",
    "    images = []\n",
    "    temp = []\n",
    "    for i in range(len(folders)):\n",
    "        randomImages = []\n",
    "        imgAddress = path + folders[i]\n",
    "        l = os.listdir(imgAddress)\n",
    "        for img in l:\n",
    "            frame = cv.imread(imgAddress+'/'+img)\n",
    "            temp.append((i,frame))\n",
    "    random.shuffle(temp)\n",
    "    for x in temp:\n",
    "        temp1, temp2 = (x)\n",
    "        labels.append(temp1)\n",
    "        images.append(temp2)\n",
    "    labels = getOneHot(np.asarray(labels))\n",
    "    images = np.asarray(images)\n",
    "    return images, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(a):\n",
    "    b = []\n",
    "    for action_frame in a:\n",
    "        hsv = cv.cvtColor(action_frame, cv.COLOR_BGR2HSV)\n",
    "        lower_color = np.array([0, 10, 60])\n",
    "        upper_color = np.array([20, 150, 255])\n",
    "        mask = cv.inRange(hsv, lower_color, upper_color) \n",
    "        res = cv.bitwise_and(action_frame,action_frame, mask= mask)\n",
    "        b.append(res)\n",
    "    return b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelNames = ['next', 'previous', 'stop']\n",
    "x_train, y_train = getData('finalImageGeneric', labelNames)\n",
    "x_val, y_val = getData('finalImageGenericVal', labelNames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.asarray(preprocess(x_train))\n",
    "x_val = np.asarray(preprocess(x_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def showImg(images, labels, labelNames):\n",
    "    plt.figure(figsize=(10,10))\n",
    "    for i in range(25):\n",
    "        plt.subplot(5,5,i+1)\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        plt.grid(False)\n",
    "        n = random.randint(0,len(images))\n",
    "        plt.imshow(images[n])\n",
    "        plt.xlabel(labelNames[np.argmax(labels[n])])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Training data:\")\n",
    "showImg(x_train, y_train, labelNames)\n",
    "print(\"Validation data:\")\n",
    "showImg(x_val, y_val, labelNames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(layer1Filter = 16, layer2Filter = 32, layer3Filter = 64, layer4Output = 400, optim = 'adam'):\n",
    "    x = Input((50, 50, 3))\n",
    "    model = BatchNormalization(axis = 3)(x)\n",
    "    model = Convolution2D(filters = layer1Filter, kernel_size = (3,3), activation='relu')(model)\n",
    "    model = MaxPooling2D()(model)\n",
    "    model = Dropout(0.5, seed = seed_value)(model)\n",
    "    \n",
    "    model = BatchNormalization(axis = 3)(model)\n",
    "    model = Convolution2D(filters = layer2Filter, kernel_size = (3,3), activation='relu')(model)\n",
    "    model = MaxPooling2D()(model)\n",
    "    model = Dropout(0.5, seed = seed_value)(model)\n",
    "    \n",
    "    model = BatchNormalization(axis = 3)(model)\n",
    "    model = Convolution2D(filters = layer3Filter, kernel_size = (3,3), activation='relu')(model)\n",
    "    model = MaxPooling2D()(model)\n",
    "    model = Dropout(0.5, seed = seed_value)(model)\n",
    "    \n",
    "    model = Flatten()(model)\n",
    "    model = Dense(layer4Output , activation = 'relu')(model)\n",
    "    model = Dropout(0.5, seed = seed_value)(model)\n",
    "    model = Dense(3, activation = 'softmax')(model)\n",
    "    \n",
    "    model = Model(input = x, output = model)\n",
    "    \n",
    "    if optim == 'adam':\n",
    "        opt = keras.optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "    else:\n",
    "        opt = keras.optimizers.RMSprop(learning_rate=0.001, rho=0.9)\n",
    "        \n",
    "    model.compile(opt, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_callbacks(name_weights, patience_lr):\n",
    "    mcp_save = ModelCheckpoint(name_weights, save_best_only=True, monitor='val_loss', mode='min')\n",
    "    reduce_lr_loss = ReduceLROnPlateau(monitor='val_accuracy', factor=0.75, patience=patience_lr, verbose=1, epsilon=1e-4)\n",
    "    return [mcp_save, reduce_lr_loss]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(x_train, y_train, x_val, y_val, layer4Output, optim, epochs):\n",
    "    name_weights = \"final_model_weights_\"+optim+\"_\"+str(layer4Output)+\".h5\"\n",
    "    model = get_model(layer4Output = layer4Output, optim = optim)\n",
    "    callbacks = get_callbacks(name_weights = name_weights, patience_lr=2)\n",
    "    history = model.fit(x = x_train, y = y_train, validation_data = (x_val, y_val), epochs = epochs, callbacks=callbacks)\n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# layer4 = [200, 400, 500, 700, 1000, 1200]\n",
    "# optimizers = ['adam', 'rmsprop']\n",
    "# scores = []\n",
    "# for optim in optimizers:\n",
    "#     for nLayer in layer4:\n",
    "#         temp = [optim, nLayer]\n",
    "#         model = train_model(x_train, y_train, x_val, y_val, nLayer, optim, 20)\n",
    "#         val = model.evaluate(x_val, y_val)\n",
    "#         temp.append(val)\n",
    "#         scores.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model, history = train_model(x_train, y_train, x_val, y_val, 400, 'adam', 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"Unable to capture video\")\n",
    "        break\n",
    "    frame = cv.flip( frame, 1 )\n",
    "    frame2 = cv.resize(frame, (50, 50))\n",
    "    a = []\n",
    "    a.append(frame2)\n",
    "    a = np.array(preprocess(a))\n",
    "    prob = model.predict(a)\n",
    "    pred = np.argmax(prob)\n",
    "    if prob[0][pred] < 0.9:\n",
    "        s = \"Background \" + str(prob[0])\n",
    "    else:\n",
    "        s = labelNames[pred] + \" \" + str(prob[0][pred])\n",
    "    font = cv.FONT_HERSHEY_SIMPLEX\n",
    "    cv.putText(frame,s,(40,40),font,0.70,(0,0,255),2)\n",
    "    cv.imshow('frame', frame)\n",
    "    cv.imshow('frame2', a[0])\n",
    "    if cv.waitKey(10) & 0xFF == ord('q'):\n",
    "        break \n",
    "\n",
    "cap.release()\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_trained_model(weights_path):\n",
    "    model= get_model()\n",
    "    model.load_weights(weights_path)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_trained_model(\"/home/ankit/Desktop/Acad/Sem/Sem5/COL780/Assn/4/weights/final_model_weights_adam_400.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
